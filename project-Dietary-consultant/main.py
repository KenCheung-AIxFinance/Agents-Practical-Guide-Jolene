"""
Main entry point for the Dietary Consultant application.
"""
from langchain.agents.middleware.types import AgentState


from typing import Any


import os

from langchain.agents import create_agent
from langchain_core.messages import HumanMessage
from langchain_deepseek import ChatDeepSeek
import dotenv
from langgraph.checkpoint.memory import InMemorySaver
from langchain_community.tools import DuckDuckGoSearchResults
from langchain.agents.middleware import HumanInTheLoopMiddleware

# Local imports
from src.utils.workflow_utils import print_workflow_steps
from langchain.tools import tool


# Initialize environment and LLM
dotenv.load_dotenv()
print("Loading DeepSeek LLM...")
# print(f"Environment variables: {os.environ.get('DEEPSEEK_API_KEY')}")
llm = ChatDeepSeek(model_name="deepseek-chat", temperature=0.7)
# print(f"LLM initialized with API key: {llm.api_key}")


search_tool = DuckDuckGoSearchResults(output_format="list")

@tool()
def calculate_bmi(height_cm: float, weight_kg: float) -> str:
    """Calculate BMI based on height (cm) and weight (kg)."""
    try:
        height = float(height_cm) / 100
        weight = float(weight_kg)
        bmi = weight / (height ** 2)
        return f"BMI ç‚º {bmi:.2f}"
    except Exception as e:
        return f"éŒ¯èª¤ï¼š{str(e)}"

@tool
def get_runtime_datetime() -> dict:
    """
    Get current datetime from the runtime machine.
    """
    from datetime import datetime
    import socket
    import os

    now = datetime.now()

    return {
        "datetime": now.isoformat(),
        "hostname": socket.gethostname(),
        "runtime_id": os.getenv("RUNTIME_ID", "unknown")
    }


@tool()
def send_email_tool(recipient: str, subject: str, body: str) -> str:
    """Mock function to send an email."""
    return f"Email sent to {recipient} with subject '{subject}'"

# Initialize components
tools = [calculate_bmi, search_tool, get_runtime_datetime, send_email_tool]


hitl_middleware = HumanInTheLoopMiddleware[AgentState, None](
    interrupt_on={
        "send_email_tool": {
            "allowed_decisions": ["approve", "edit", "reject"],
        },
        "calculate_bmi":{
            "allowed_decisions": ["approve", "reject"]
        }
    }
)


def create_dietary_agent(
        llm,
        tools,
        checkpointer,
        debug: bool = False
):
    """Create a new agent with the given configuration.

    Args:
        llm: The language model to use
        tools: List of tools the agent can use
        checkpointer: Checkpoint saver for conversation history
        debug: Whether to enable debug mode

    Returns:
        The configured agent
    """
    agent_prompt = """ä½ æ˜¯ä¸€ä½è¦ªåˆ‡çš„å°ˆæ¥­è†³é£Ÿç‡Ÿé¤Šé¡§å•ï¼Œå°ˆé•·æ–¼å…’ç«¥èˆ‡é’å°‘å¹´ç‡Ÿé¤Šã€‚

ä½ çš„ä»»å‹™ï¼š
1. å¦‚æœä½¿ç”¨è€…å°šæœªæä¾›ã€Œå¹´é½¡ã€æ€§åˆ¥ã€èº«é«˜ï¼ˆcmï¼‰ã€é«”é‡ï¼ˆkgï¼‰ã€ï¼Œè«‹æº«å’Œåœ°å¼•å°ä»–å€‘æä¾›é€™äº›è³‡è¨Šã€‚
   - ä¾‹å¦‚ï¼šã€Œç‚ºäº†çµ¦æ‚¨åˆé©çš„å»ºè­°ï¼Œå¯ä»¥å‘Šè¨´æˆ‘æ‚¨çš„å¹´é½¡ã€æ€§åˆ¥ã€èº«é«˜å’Œé«”é‡å—ï¼Ÿã€
2. ä¸€æ—¦ç²å¾—è¶³å¤ è³‡è¨Šï¼Œå¯ä¸»å‹•è¨ˆç®— BMIï¼ˆä½¿ç”¨å·¥å…·ï¼‰ï¼Œä¸¦æä¾›ï¼š
   - BMI æ•¸å€¼èˆ‡å…’ç«¥æ¨™æº–è§£è®€ï¼ˆåƒè€ƒè¡›ç¦éƒ¨æˆ– WHO æ¨™æº–ï¼‰
   - æ¯æ—¥å»ºè­°ç†±é‡
   - é£²é£Ÿèˆ‡ç”Ÿæ´»å»ºè­°
3. ä¿æŒèªæ°£å‹å–„ã€é¼“å‹µï¼Œé¿å…ä½¿ç”¨åš‡äººè©å½™ï¼ˆå¦‚ã€Œè‚¥èƒ–ã€ã€Œéç˜¦ã€ï¼‰ï¼Œæ”¹ç”¨ã€Œç‡Ÿé¤Šå‡è¡¡ã€ã€Œå¥åº·æˆé•·ã€ç­‰ã€‚

è«‹æ ¹æ“šå°è©±ä¸Šä¸‹æ–‡æ±ºå®šæ˜¯å¦éœ€è¦å·¥å…·å”åŠ©ã€‚"""
    if (checkpointer == None):
        return create_agent(
        model=llm,
        tools=tools,
        system_prompt=agent_prompt,
        middleware=[hitl_middleware],
        debug=debug
    )
    return create_agent(
        model=llm,
        tools=tools,
        system_prompt=agent_prompt,
        checkpointer=checkpointer,
        middleware=[hitl_middleware],
        debug=debug
    )

# agent = create_dietary_agent(llm=llm, tools=tools, checkpointer=InMemorySaver(), debug=True)

agent = create_dietary_agent(llm=llm, tools=tools, checkpointer=None, debug=True)
# config = get_agent_config()

if __name__ == '__main__':
    # ===== å„ªåŒ–å¾Œçš„äº’å‹•ä¸»è¿´åœˆ =====
    # ===== ä¸»äº’å‹•è¿´åœˆï¼ˆç„¡é è¨­å•é¡Œï¼‰=====
    print("ğŸ‘‹ æ­¡è¿ä½¿ç”¨å…’ç«¥ç‡Ÿé¤Šè«®è©¢æœå‹™ï¼")
    print("æ‚¨å¯ä»¥è¼¸å…¥ä»»ä½•å•é¡Œï¼Œä¾‹å¦‚ï¼š")
    print("  â€¢ ã€Œæˆ‘10æ­²ï¼Œå¥³ç”Ÿï¼Œèº«é«˜138é«”é‡29ã€")
    print("  â€¢ ã€Œæ€éº¼åˆ¤æ–·å°å­©é«”é‡æ˜¯å¦æ­£å¸¸ï¼Ÿã€")
    print("  â€¢ ã€ŒBMI æ˜¯ä»€éº¼ï¼Ÿã€")
    print("è¼¸å…¥ 'quit' å¯éš¨æ™‚çµæŸã€‚\n")
    while True:
        user_input = input("\nä½ ï¼š").strip()
        if user_input.lower() in ["quit", "exit", "çµæŸ"]:
            print("ğŸ‘‹ å†è¦‹ï¼")
            break

        # å‚³é€æ–°è¨Šæ¯ä¸¦å–å¾—å®Œæ•´åŸ·è¡Œè»Œè·¡
        response = agent.invoke(
            {"messages": [HumanMessage(content=user_input)]},
            {"configurable": {"thread_id": 1}}
        )

        # é¡¯ç¤ºå®Œæ•´ workflow æ­¥é©Ÿï¼ˆå«æ¨ç†ã€å·¥å…·èª¿ç”¨ã€çµæœï¼‰
        print_workflow_steps(response["messages"])
        pass

"""
1. è§£é‡‹ä»£ç¢¼
2. ä½ å¯«ä»£ç¢¼
3. ä½ ç•«åœ–å»è¡¨é”ä»£ç¢¼çš„çµæ§‹
4. æ·»åŠ ä»£ç¢¼ï¼šå¯¦éš›é‹è¡Œ
"""

"""
TODO:
è®“ AI Agentä¸»å‹•çš„æŸ¥çœ‹ä¸¦é–±è®€é—œæ–¼å®¶äººä¿¡æ¯çš„æ–‡ä»¶
"""